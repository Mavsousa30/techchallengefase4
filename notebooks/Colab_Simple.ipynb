{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67ce2c9d",
   "metadata": {},
   "source": [
    "# ğŸ¬ Tech Challenge Fase 4 - VersÃ£o Simplificada\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Mavsousa30/techchallengefase4/blob/main/notebooks/Colab_Simple.ipynb)\n",
    "\n",
    "## âš¡ IMPORTANTE:\n",
    "1. **Ative a GPU**: Runtime â†’ Change runtime type â†’ GPU (T4)\n",
    "2. **Execute TODAS as cÃ©lulas em ordem**\n",
    "3. Aguarde downloads na primeira execuÃ§Ã£o (~2-3 min)\n",
    "\n",
    "## ğŸ“‹ O que este notebook faz:\n",
    "- âœ… Detecta rostos\n",
    "- âœ… Classifica emoÃ§Ãµes\n",
    "- âœ… Reconhece atividades\n",
    "- âœ… Gera relatÃ³rios\n",
    "\n",
    "**Tempo estimado**: 5-10 min para vÃ­deo de 1 minuto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f3388c",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Setup Completo (Execute esta cÃ©lula primeiro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b14b094",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Instalar dependÃªncias\n",
    "!pip install -q opencv-python numpy pandas deepface torch torchvision tqdm pydantic rich\n",
    "\n",
    "# Clonar repositÃ³rio\n",
    "!rm -rf techchallengefase4\n",
    "!git clone https://github.com/Mavsousa30/techchallengefase4.git\n",
    "\n",
    "# Mudar para o diretÃ³rio PRIMEIRO\n",
    "%cd techchallengefase4\n",
    "\n",
    "# DEPOIS criar diretÃ³rios (no lugar certo)\n",
    "import os\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "os.makedirs('outputs/logs', exist_ok=True)\n",
    "os.makedirs('outputs/frames', exist_ok=True)\n",
    "\n",
    "print('âœ… Setup concluÃ­do!')\n",
    "print(f'ğŸ“‚ DiretÃ³rio: {os.getcwd()}')\n",
    "print(f'ğŸ“ outputs/ existe: {os.path.exists(\"outputs\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dede09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar GPU e recursos\n",
    "import torch\n",
    "import psutil\n",
    "\n",
    "print('ğŸ® GPU:')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'   âœ… {torch.cuda.get_device_name(0)}')\n",
    "    print(f'   ğŸ’¾ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')\n",
    "else:\n",
    "    print('   âš ï¸  Nenhuma GPU - SerÃ¡ mais lento!')\n",
    "    print('   ğŸ’¡ Ative: Runtime â†’ Change runtime type â†’ GPU')\n",
    "\n",
    "print(f'\\nğŸ’¾ RAM: {psutil.virtual_memory().total / 1e9:.1f} GB')\n",
    "print(f'ğŸ–¥ï¸  CPU: {psutil.cpu_count()} cores')\n",
    "print(f'\\nğŸ“‚ DiretÃ³rio: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219b1d41",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Upload do VÃ­deo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa839283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print('ğŸ“¤ Selecione seu vÃ­deo (MP4, AVI, MOV, MKV):')\n",
    "uploaded = files.upload()\n",
    "\n",
    "video_file = list(uploaded.keys())[0]\n",
    "video_size = len(uploaded[video_file]) / (1024**2)\n",
    "\n",
    "print(f'\\nâœ… Upload concluÃ­do!')\n",
    "print(f'ğŸ“¹ Arquivo: {video_file}')\n",
    "print(f'ğŸ“Š Tamanho: {video_size:.2f} MB')\n",
    "\n",
    "if video_size > 100:\n",
    "    print('\\nâš ï¸  VÃ­deo grande! Processamento pode demorar.')\n",
    "    print('ğŸ’¡ Dica: Use vÃ­deos < 2 minutos para testes rÃ¡pidos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786140fc",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Processar VÃ­deo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bf7ca7",
   "metadata": {},
   "source": [
    "### ğŸ”§ Nota sobre Codec de VÃ­deo\n",
    "\n",
    "Se encontrar erro `VideoWriterError: Failed to write frame`, pode ser um problema de codec.\n",
    "O notebook usa `mp4v` por padrÃ£o, que funciona na maioria dos casos.\n",
    "\n",
    "**Se tiver problemas, nÃ£o se preocupe** - os relatÃ³rios JSON e MD serÃ£o gerados normalmente!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff5f4b0",
   "metadata": {},
   "source": [
    "### ğŸ§ª DiagnÃ³stico (Execute se tiver problemas)\n",
    "\n",
    "Se encontrar erro de VideoWriter, execute a cÃ©lula abaixo para diagnosticar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34c1626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§ª DIAGNÃ“STICO COMPLETO - Execute se tiver erro VideoWriterError\n",
    "!python test_videowriter_colab.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450db9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar mÃ³dulos\n",
    "import sys\n",
    "sys.path.insert(0, '/content/techchallengefase4')\n",
    "\n",
    "from src.pipeline.inference import InferencePipeline\n",
    "from src.metrics.reporter import Reporter\n",
    "\n",
    "print('âœ… MÃ³dulos importados!')\n",
    "print('ğŸ¬ Iniciando processamento...\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd430f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” VERIFICAÃ‡ÃƒO: Garantir que tudo estÃ¡ no lugar certo\n",
    "import os\n",
    "\n",
    "print('ğŸ” Verificando ambiente...')\n",
    "print(f'ğŸ“‚ DiretÃ³rio atual: {os.getcwd()}')\n",
    "print(f'ğŸ“ outputs/ existe: {os.path.exists(\"outputs\")}')\n",
    "print(f'ğŸ“ src/ existe: {os.path.exists(\"src\")}')\n",
    "\n",
    "# Criar outputs se nÃ£o existir (garantia extra)\n",
    "if not os.path.exists('outputs'):\n",
    "    print('âš ï¸  Criando diretÃ³rio outputs...')\n",
    "    os.makedirs('outputs', exist_ok=True)\n",
    "    os.makedirs('outputs/logs', exist_ok=True)\n",
    "    os.makedirs('outputs/frames', exist_ok=True)\n",
    "\n",
    "# Testar se consegue escrever\n",
    "test_file = 'outputs/test_write.txt'\n",
    "try:\n",
    "    with open(test_file, 'w') as f:\n",
    "        f.write('test')\n",
    "    os.remove(test_file)\n",
    "    print('âœ… PermissÃµes de escrita OK!')\n",
    "except Exception as e:\n",
    "    print(f'âŒ Erro ao escrever: {e}')\n",
    "\n",
    "print('\\nâœ… Ambiente verificado! Pronto para processar.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7a68ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar e executar pipeline\n",
    "pipeline = InferencePipeline(\n",
    "    video_path=video_file,\n",
    "    output_video_path='outputs/annotated.mp4',\n",
    "    save_preview=True,\n",
    "    face_backend='opencv',\n",
    "    emotion_backend='deepface'\n",
    ")\n",
    "\n",
    "# Processar (pode demorar alguns minutos)\n",
    "summary = pipeline.run()\n",
    "\n",
    "print('\\nğŸ‰ Processamento concluÃ­do!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4375722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”§ ALTERNATIVA: Se o vÃ­deo anotado der erro, use esta cÃ©lula\n",
    "# Processa SEM salvar vÃ­deo (apenas gera mÃ©tricas e relatÃ³rios)\n",
    "\n",
    "# pipeline = InferencePipeline(\n",
    "#     video_path=video_file,\n",
    "#     output_video_path=None,  # NÃ£o salvar vÃ­deo\n",
    "#     save_preview=False,       # Desabilitar preview\n",
    "#     face_backend='opencv',\n",
    "#     emotion_backend='deepface'\n",
    "# )\n",
    "# \n",
    "# summary = pipeline.run()\n",
    "# print('\\nâœ… Processamento concluÃ­do (sem vÃ­deo anotado)!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2603c5a1",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6919f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar resumo\n",
    "print('ğŸ“Š RESUMO DO PROCESSAMENTO')\n",
    "print('=' * 60)\n",
    "print(f'ğŸ“¹ VÃ­deo: {summary[\"video_path\"]}')\n",
    "print(f'ğŸï¸  Frames: {summary[\"frames_total\"]:,}')\n",
    "print(f'â±ï¸  DuraÃ§Ã£o: {summary[\"duration_seconds\"]:.2f}s')\n",
    "print(f'ğŸ¯ FPS: {summary[\"fps\"]:.2f}')\n",
    "print(f'\\nğŸ‘¤ FACES')\n",
    "print(f'   Total: {summary[\"faces_stats\"][\"total\"]}')\n",
    "print(f'   MÃ©dia/frame: {summary[\"faces_stats\"][\"mean_per_frame\"]:.2f}')\n",
    "print(f'   MÃ¡ximo: {summary[\"faces_stats\"][\"max_in_frame\"]}')\n",
    "\n",
    "if summary['emotions_distribution']:\n",
    "    print(f'\\nğŸ˜Š EMOÃ‡Ã•ES')\n",
    "    for emotion, count in sorted(summary['emotions_distribution'].items(), \n",
    "                                   key=lambda x: x[1], reverse=True)[:5]:\n",
    "        print(f'   {emotion}: {count}')\n",
    "\n",
    "if summary['activities_timeline']:\n",
    "    print(f'\\nğŸ­ ATIVIDADES: {len(summary[\"activities_timeline\"])} eventos')\n",
    "\n",
    "print(f'\\nâš ï¸  ANOMALIAS: {summary[\"anomalies_total\"]}')\n",
    "print('=' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdf5ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar vÃ­deo anotado\n",
    "from IPython.display import Video\n",
    "\n",
    "print('ğŸ¬ VÃ­deo com AnotaÃ§Ãµes:')\n",
    "Video('outputs/annotated.mp4', width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698d5509",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ Gerar RelatÃ³rios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374e556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar relatÃ³rios\n",
    "reporter = Reporter()\n",
    "reporter.save_metrics(summary, 'outputs/metrics.json')\n",
    "reporter.generate_markdown_report(summary, 'outputs/report.md')\n",
    "\n",
    "print('âœ… RelatÃ³rios gerados:')\n",
    "print('   ğŸ“„ outputs/metrics.json')\n",
    "print('   ğŸ“„ outputs/report.md')\n",
    "print('   ğŸ¬ outputs/annotated.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6b62a2",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ Download dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12100c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import zipfile\n",
    "\n",
    "# Criar ZIP\n",
    "zip_file = 'resultados.zip'\n",
    "with zipfile.ZipFile(zip_file, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    zipf.write('outputs/annotated.mp4', 'annotated.mp4')\n",
    "    zipf.write('outputs/metrics.json', 'metrics.json')\n",
    "    zipf.write('outputs/report.md', 'report.md')\n",
    "\n",
    "import os\n",
    "size = os.path.getsize(zip_file) / (1024**2)\n",
    "print(f'ğŸ“¦ Arquivo criado: {zip_file} ({size:.2f} MB)')\n",
    "print('â¬‡ï¸  Iniciando download...')\n",
    "\n",
    "files.download(zip_file)\n",
    "print('âœ… Download concluÃ­do!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb87cdbc",
   "metadata": {},
   "source": [
    "## ğŸ“Š AnÃ¡lise Extra (Opcional)\n",
    "\n",
    "GrÃ¡ficos de emoÃ§Ãµes e atividades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2347ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# GrÃ¡fico de emoÃ§Ãµes\n",
    "if summary['emotions_distribution']:\n",
    "    emotions = dict(sorted(summary['emotions_distribution'].items(), \n",
    "                           key=lambda x: x[1], reverse=True)[:7])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    bars = ax.bar(emotions.keys(), emotions.values(), color='skyblue', edgecolor='navy')\n",
    "    \n",
    "    # Adicionar valores nas barras\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{int(height)}',\n",
    "                ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    ax.set_xlabel('EmoÃ§Ã£o', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('FrequÃªncia', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('DistribuiÃ§Ã£o de EmoÃ§Ãµes Detectadas', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('âš ï¸  Nenhuma emoÃ§Ã£o detectada')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908c8686",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… ConcluÃ­do!\n",
    "\n",
    "### ğŸ“š Recursos:\n",
    "- [RepositÃ³rio GitHub](https://github.com/Mavsousa30/techchallengefase4)\n",
    "- [DocumentaÃ§Ã£o](https://github.com/Mavsousa30/techchallengefase4/blob/main/README.md)\n",
    "- [Troubleshooting](https://github.com/Mavsousa30/techchallengefase4/blob/main/notebooks/TROUBLESHOOTING_COLAB.md)\n",
    "\n",
    "### ğŸ’¡ Dicas:\n",
    "- Para processar outro vÃ­deo, execute apenas as cÃ©lulas 2-6\n",
    "- Use GPU (T4) para melhor performance\n",
    "- VÃ­deos curtos (< 2 min) sÃ£o processados mais rÃ¡pido\n",
    "\n",
    "**ğŸ‰ Obrigado por usar o Tech Challenge Fase 4!**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
